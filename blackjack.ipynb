{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb191f90",
   "metadata": {},
   "source": [
    "# Reinforced learning - Blackjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d07804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from BlackjackAgent import BlackjackMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85ab37",
   "metadata": {},
   "source": [
    "### Wstępne sprawdzenie działania środowiska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Blackjack-v1\", render_mode=\"human\", sab=True) # sab=True -> wersja z obsługą „natural blackjack” i dokładną specyfiką polityk\n",
    "observation, info = env.reset()\n",
    "\n",
    "episode_over = False\n",
    "while not episode_over:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    print(f\"State: {observation}, Action: {action}, Reward: {reward}\")\n",
    "\n",
    "    episode_over = terminated or truncated\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220894cc",
   "metadata": {},
   "source": [
    "### Trenowanie agenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Blackjack-v1\", sab=True)\n",
    "agent = BlackjackMC(env, epsilon=0.1, discount_factor=0.9)\n",
    "agent.train(500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d17ea4",
   "metadata": {},
   "source": [
    "### Testy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811110a9",
   "metadata": {},
   "source": [
    "##### Krzywa uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_avg = np.convolve(agent.reward_history, np.ones(1000)/1000, mode='valid')\n",
    "plt.plot(rolling_avg)\n",
    "plt.title(\"Średnia nagroda agenta w czasie\")\n",
    "plt.xlabel(\"Epizod\")\n",
    "plt.ylabel(\"Średnia nagroda\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d126209",
   "metadata": {},
   "source": [
    "##### Polityka podejmowania decyzji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_ace = np.zeros((21 - 3, 10))  # player sum 4-21, dealer 1-10\n",
    "no_usable_ace = np.zeros((21 - 3, 10))\n",
    "\n",
    "for player in range(4, 22):\n",
    "    for dealer in range(1, 11):\n",
    "        state = (player, dealer, 1)\n",
    "        usable_ace[player - 4, dealer - 1] = agent.get_action(state)\n",
    "\n",
    "        state = (player, dealer, 0)\n",
    "        no_usable_ace[player - 4, dealer - 1] = agent.get_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f898c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(8, 6)\n",
    "\n",
    "ax1.imshow(usable_ace, cmap='gray', extent=[1, 10, 4, 21])\n",
    "ax1.set_title('Jeśli gracz posiada używalnego asa')\n",
    "ax1.set_xlabel(\"Karta krupiera\")\n",
    "ax1.set_xticks(ticks=np.arange(1, 11, 1))\n",
    "ax1.set_ylabel(\"Suma wartości kart gracza\")\n",
    "ax1.set_yticks(ticks=np.arange(4, 22, 1))\n",
    "\n",
    "ax2.imshow(no_usable_ace, cmap='gray', extent=[1, 10, 4, 21])\n",
    "ax2.set_title('Jeśli gracz nie posiada używalnego asa')\n",
    "ax2.set_xlabel(\"Karta krupiera\")\n",
    "ax2.set_xticks(ticks=np.arange(1, 11, 1))\n",
    "ax2.set_ylabel(\"Suma wartości kart gracza\")\n",
    "_ = ax2.set_yticks(ticks=np.arange(4, 22, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225c1e8",
   "metadata": {},
   "source": [
    "##### Performance agenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(num_episodes: int, policy):\n",
    "    wins, draws, losses = 0, 0, 0\n",
    "    for _ in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy(state)\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            state = next_state\n",
    "        if reward == 1:\n",
    "            wins += 1\n",
    "        elif reward == 0:\n",
    "            draws += 1\n",
    "        else:\n",
    "            losses += 1\n",
    "    return wins, draws, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1bc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000\n",
    "wins, draws, losses = simulate(num_episodes, agent.get_action)\n",
    "print(\"Wytrenowany agent:\")\n",
    "print(f\"Wygrane: {wins} ({(wins / num_episodes * 100):.2f}%)\")\n",
    "print(f\"Remisy: {draws} ({(draws / num_episodes * 100):.2f}%)\")\n",
    "print(f\"Przegrane: {losses} ({(losses / num_episodes * 100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000\n",
    "wins, draws, losses = simulate(num_episodes, lambda _: env.action_space.sample())\n",
    "print(\"Losowy agent:\")\n",
    "print(f\"Wygrane: {wins} ({(wins / num_episodes * 100):.2f}%)\")\n",
    "print(f\"Remisy: {draws} ({(draws / num_episodes * 100):.2f}%)\")\n",
    "print(f\"Przegrane: {losses} ({(losses / num_episodes * 100):.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
